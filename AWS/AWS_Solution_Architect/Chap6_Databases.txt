Dababases 101
    1. Relastional databases on AWS
        -> runs on virtual machines
        -> cannot ssh (or remoting)
        -> cannot login to patching
            RDS vs EC2 patching responsibility:
                -> RDS: AWS responible to path both OS and database
                -> EC2: share responsibility 
        -> RDS is NOT serverless (Aurora is serverless)
        Supported DB:
            -> SQL Server
            -> Oracle
            -> MySQL Server (what we use for this lab)
            -> PostgreSQL
            -> Aurora
            -> MariaDB
        Types: Multiple AZs vs Read Replicas
            - Multi-AZ - to have an exact copy of the production database in another AZ
                + AWS handles replication: 
                    -> writting on production database will automatically be synchronized to the 2nd/stand-by database
                + failover when:
                    -> database maintenance
                    -> database instance failure
                    -> AZ failure
                + failover how:
                    -> AWS will automatically update the IP address to the stand-by database - still using
                        the current DNS string (AWS will handle failover)
                    -> operation can resume quickly - less downtime
                    -> requires no administrative intervention
                + why:
                    -> Disaster Recovery for HA DB
                    -> Good for important DB
                + Failover automatically:
                    + EC2 connect to Primary DB via connecting DNS string 
                    + When Primary DB is down, AWS will automatically create/update another connecting DNS string from EC2 to 
                        the Secondary DB
                + Supported database: everything but Aurora (Aurora has its own faul-tolerence)
                    SQL Server, Oracle, MySQL Server, PostgreSQL, MariaDB
            - Read Replicas - create multiple RDS replica to handle high read requests
                + High Read requests:
                    -> Some database has a lot of Read traffic that can bottle neck its resource/network
                + Solution:
                    -> Replicate the Primary database to multiple read-only database instances - Asynchronous Replication
                    -> Redirect all the Read Requests pan out on all the Read-Replicas database instances
                    -> Only write to the Primary so that it can be replicated our to Replicas - Asynchronous Replication
                -> used for scaling not recovery
                -> must have automatic backups turned on to deploy a read replica
                -> can have up to 5 read replica copies per database
                -> can have Read-replica of Read-replica (watchout for latency)
                -> Each RR has its own DNS endpoint (unlike Multi-AZ)
                -> RR can be Multi-AZ
                -> RR can be created on Multi-AZ databases
                -> RR can be promoted to be their own data but replication will be breaks
                -> RR can be created in second Region
                -> Failover isn't auto:
                    + EC2 connect to Primary DB via connecting DNS string 
                    + When Primary is down, user have to create new URL + manually update DNS on Read Replicas DB
    2. Non Relational Databases
        -> 
    3. Relational DB vs Non-relational DB
    4. Data Warehousing
        -> use for Business Intelligence BI
        -> use to pull in large complex data sets
        -> for management do queries on data
        Online Transaction Processing (OLTP) vs Online Analytics Processing (OLAP)
            OLTP:
                -> small, specific query
                -> contain specific product ID, personal info, etc.
            OLAP:
                -> big, complex number of queries
                -> pull in large number of records
        -> use different type of Architecture both from database perspective and infrastructure Layer
        -> AWS Redshift



RDS - Relational Database Service
    Backups - Automated Backups vs Database snapshots
        Automated Backups:
            -> allow to recover db to any point in time within Retention Period
            -> Retention Period 1-35 days
            -> How:
                -> Automated Backups take: full daily snapshots + store daily transaction logs
                -> recover: choose the most recent daily backup -> apply transaction logs 
            -> allow to recover a point in time recovery down to a second
            -> enable by default
            -> backups store in S3 for free
            -> S3 size = DB size
            -> during backups window, I/O may suspend or elevated latency
        Snapshots
            -> manual (not automate)
            -> save after DB is deleted
            -> restoring a snapshot will be restored on a new RDS instance with a new DNS endpoint
    Encryption At Rest
        - Supported on:
            + MySQL
            + Oracle
            + SQL Server
            + PostgreSQL
            + MariaDB
            + Aurora
        - using Key Management Service (KMS)
        - once RDS instance is encrypted -> all data stored at rest underlying storage is also encrypted:
            + automated backup
            + read Replicas
            + snapshots 

Dynamo DB - AWS Non Relational Database
    What is Dynamo DB?
        - Fast and flexible NoSQL database service
        - For apps needs: consistent, single-digit millisecond latency
        - fully managed database
        - support document models
        - support key-value models
        - flexible + reliable performance
        - for: mobile, web, gaming, ad-tech, IoT, etc.
    -> store on SSD
    -> spread across 3 geographically disctint data center
    -> Eventual Consistent Read: read after write within 1 second - Best read performance
    -> Strongly Consistent Read:  read after write less than 1 second

Advanced DynamoDB
    DynamoDB Accelerator (DAX)
        -> managed, HA, in-memory cache
        -> 10x performance improvement compares to using DynamoDB
        -> reduce request time from milliseconds to microseconds (even under load)
        -> no need to managed caching locagical
        -> combatiple with exist DynamoDB APIs call
        - Traditional caching vs DAX caching:
            -> Traditional:
                + Cache sit off to the side of the application
                + Have to be managed
                + Only support read
            -> DAX:
                + Cache sit between application and DynamoDB
                + No need to be managed
                + Write-through-cache support write
                + HA

    Transactions
        The problems: In all-for-nothing operations, some requests have to happen at the same time
            simutaneously where one fail to happen the other will also fail to happen
        Example: Financial transactions (credit-debit), Fullfilling orders (E-commerce)
        The solutions: 
            -> DynamoDB will perform read or write -> prepare/commit
            -> consume more capacity
            -> up to 25 items or 4MB of data

    On-Demand Capacity
        Pay-per-request pricing vs Provisioning pricing
            Per-per-request:
                Only pay what you use
                Easy to balance cost and performance
                No minimum capacity
            Provisioning
                Change on storage and backups - no charge for read-write
        -> Pay-per-request is more expensive, use for new product launches, when it stable, change to Provisioning

    On-Demand Backup and Restore
        -> Full backups at anytime
        -> zero impact on table performance and availability (unlike RDS)
        -> consistent within seconds + retained until deleted
        -> operate within same region only
        
        Point-in-Time Recovery (PITR)
            -> to protect agaisnt accidental writes or deletes
            -> restores within 35 days
            -> incremental backups
            -> not enable by default
            -> latest restorable = 5 minutes
    
    Stream - Time-ordered sequence of item-level changes in a table
        DynamoDB Stream (Shard(Stream Records))
            -> A DynamoDB(Shard1, Shard2, Shard3, Shardn)
                    Shard(StreamRecords1, StreamRecords2, StreamRecordsn)
        -> Store for 24 hours
        -> Insert, updates, and deletes
        -> combine with lambda
    
    Global Tables
        -> globally distributed applications
        -> based on DynamoDB streams
        -> muti-region redundancy for Disaster Recovery or HA
        -> no application rewrites
        -> replication latency under 1 second

    Database Migration Service (DMS)
        -> to migrate one database to another
        -> support Source database: on-prem, EC2, RDS, Aurora, S3, DB2, MariaDB, AzureDB, SQL Server
                                                    MongoDB, MySQL, Oracle, PostgreSQL, Sybase
        -> support Target database: on-prem, EC2, RDS, Aurora, DocumentDB, DynamoDB, Kinesis, Redshift,
                                                    S3, Elasticsearch, Kafka, MariaDB, SQL Server, MySQL
                                                    Oracle, PostgreSQL, Sybase
        -> source database remains operational
    
    Security
        -> KMS encrypt at rest
        -> Site-to-site VPN
        -> Direct Connect (DX)
        -> IAM policies roles
        -> Fine-grained access
        -> CloudWatch and CloudTrail
        -> VPC endpoints
            -> allow EC2 to connect to DynamoDB's private IP address
            -> no public exposure

Redshift - is AWS solution for Datawarehouse where there is a huge amount of data that need to be queried and processed

    Redshift configuration: Single Node vs Multi-Node
        -> Single node: 160GB
        -> Multi-Node: 
            + Leader Node: manages client connections and receives queries
            + Compute Nodes: store data + perform queries + computations, up to 128 Nodes

    Advanced Compression: automatically compress data

    Massively Parallel Processing (MPP):
        -> automatically distributes data and query load across all Nodes
        -> increase Compute Nodes to scale out Redshift
    
    *Backups
        -> Retention period: 1 day (default), 35 days max
        -> attemps to maintain at least 3 copies: origin + replica (on compute nodes) + a backup (on S3)
        -> can asynchronously replicate snapshots to S3 in another region (DR)

    Pricing
        -> Compute Node hours: total number of hours run across all compute nodes for 1 billing period
            For example: 3 nodes clusrer runs 30 days = 3 * 24 * 30 = 2160 instance hours
        -> charge backup
        -> charge data transfer (within VPC only, not outside)

    Security
        -> Intransit - encrypt SSL
        -> At rest - encrypt AES-256
        -> Redshift takes care of key management by default. Can be managed by:
            + your own keys through Hardware Security Module HSM
            + AWS KMS
    
    availability:
        -> only in 1 AZ
        -> can be restore to another AZ from a snapshot


Aurora
    PostgreSQL = commercial database that handle complex queries and massive database, loads with features - object-relational database(ORDBMS)
    MySQL = simpler database that easy to set up, manage, fast, reliable - pure relational database (RDBMS)
    Aurora = PostgreSQL + MySQL + cost effective
        (5x faster than MySQL, 3x faster than postgreSQL)
    -> Start with 10GB
    -> Storage Autoscaling: scale in 10GB increments to 64TB 
    -> Scaling Aurora:
        + 2 copies each AZ, minimum 3 AZs => minimum of 6 copies                                     *
        + can transparently handle loss up to 2 copies without effecting write
        + can transparently handle lose up to 3 copies without effecting read
    Self-healing: data blocks and disks are continuously scanned for erros and repaired automatically      *
        Aurora Replicas:
            Comparison
            features                                    Aurora Replicas                     MySQL                       PostgreSQL
            ============================================================================================================================
            Mumber of Replicas                          up to 15                            up to 5                     1
            Replication type                            Asynchronous(millisecond)           Asynchronous(seconds)
            Performance impact                          lower                               High
            Replication location                        In-Region                           Cross-Region
            Act as failover Target                      Yes (nodata lost)                   Yes (potentially)
            Automated failover                          Yes                                 No
            Support user-defined rep delay              No                                  Yes
            Support different data/schema vs Primary    No                                  Yes

    Aurora Backups:
        -> Automated backup enabled by default                                 *
        -> Can also take snapshot
        -> Backup and Snapshots do not impact database performance
        -> Snapshots can be share with other AWS accounts                      *                         

Aurora Serverless: is an on-demand, autoscaling configuration for MySQL-compatible and PostgreSQL-compatible edition of Amazon Aurora
    -> Aurora Serverless cluster automatically starts up, shuts down, and scales capacity up/down base on application needs
        -> for simple, cost-effective option for infrequent, intermittent, and/or unpredictable workloads                                    *
        -> use case: host a budget website, that need to be auto-scale up and down and we have no idea how the traffic will look like
    -> pay per request
    -> powerful database server but cheap

ElasticCache
    - a web service that make it easy to deploy, operate, and scale in-mem cache in cloud
    - improves web applications performance by allow information to be retrieved fast, manage, in-mem caches
    - Memcached vs Redis
        Requirement                     Memcached       Redis
        =====================================================
        Simple Cache of offload DB      Yes             Yes
        Ability to scale horizontally   Yes             Yes
        Multi-threaded performance      Yes             No
        Advance data types              No              Yes
        Ranking/Sorting data sets       No              Yes
        Pub/sub capabilities            No              Yes
        Persistence                     No              Yes
        Multi-AZ                        No              Yes
        Back/restore capabilities       No              Yes

Database Migration Service DMS
    - cloud service runs replication software
    - support: Relational Databases, Data Warehouse, NoSQL
    - support: prem-to-cloud, cloud-to-prem, prem-to-prem
    - can be migrate from another cloud platform
    - target table:
        + create manually
        + use AWS Schema Converstion Tool (SCT) -> to convert one database schema to another during migration
    - How:
        1. DMS take data from Source_database via Source_endpoint (DNS string)
        2. DMS Replicate the data within a Replication Instance
        3. DMS Push the data to Target_database through Target_endpoint (DNS string)

                                           AWS DMS
                        ==================================================
           Source       ==                                              ==     Target
           Database     == Source     ->  Replication   ->   Target     ==     Database
                        == Endpoint         Task             Endpoint   ==
                        ==                                              ==
                        ==================================================
    - Supported Types:
        -> homogenous: migrating same database type (ex: Oracle -> Oracle)
            ===========================================
            On-prem      <->   EC2 Instance     ->  RDS
            Database           Running DMS
            ===========================================

        -> heterogeneous: migrating from one database type to another (SQLServer -> Amazon Aurora) (with Schema Conversion Tool SCT)
            ===========================================
            On-prem      <->   EC2 Instance     ->  RDS
            Database           Running DMS+SCT
            ===========================================

    - Supported Sources and Targets:
        -> Sources:  
            -> On-premise and EC2 instances: Oracle, Microsoft SQL Server, MySQL, MariaDB. PostgreSQL, SAP, MongoDB, DB2
            -> Azure SQL Database
            -> Amazon RDS (including Aurora)
            -> Amazon S3
        -> Targets:
            -> On-premise and EC2 instances: Oracle, Microsoft SQL Server, MySQL, MariaDB. PostgreSQL, SAP ( no MongoDB, DB2)
            -> RDS
            -> Redshift
            -> DynamoDB
            -> S3
            -> Elasticsearch service
            -> Kinesis Data streams
            -> DocumentDB

Caching Strategy:
    Caching is a balancing act between up-to-date, accurate information and latency
    AWS service has cache:
        1. CloudFront
        2. API Gateway
        3. ElastiCache - Memcached and Redis
        4. DynamoDB Accelerator (DAX)

Elastic Map Reduced EMR
    - solution for big data 
    - processing vast amounts of data using open-source: Apache Spark, Hive, Flink, Hudi, Presto
    - petabyte-scale analysis
    - low cost (less tahn half the cost o traditional on-prem solution)

    -> Central component of EMR is cluster
        -> a cluster is a collection of EC2 instances
            -> each instances call a node
                -> each node has a role (Node Types)
                -> EMR install different software components on each node
                -> EMR distributes application work loads on compute nodes
        -> Node Types:
            + Mater node:
                + manges cluster
                + tracks status of tasks
                + monitors cluster health
                + 1 master node per cluster
            + Core node:
                + a node with EMR software components (client agents)
                + run tasks and storage data in HDFS
                    + HDFS = Hadoop Distributed File System: primary data storage system under Hadoop applications, high-throughput, big data storage
                + multi-node cluster have at least one core node
            + Task node: (optional)
                + has EMR software components (client agents)
                + only run rasks - no data store
                + optional   